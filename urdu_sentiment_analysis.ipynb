{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install LughaatNLP"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Pal_t2SbISd-",
        "outputId": "4f24fb9b-37c2-4e2f-ee22-9a19546a9c78"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting LughaatNLP\n",
            "  Downloading LughaatNLP-1.0.6-py3-none-any.whl.metadata (39 kB)\n",
            "Collecting python-Levenshtein (from LughaatNLP)\n",
            "  Downloading python_Levenshtein-0.26.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (from LughaatNLP) (2.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from LughaatNLP) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from LughaatNLP) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from LughaatNLP) (1.13.1)\n",
            "Collecting gtts (from LughaatNLP)\n",
            "  Downloading gTTS-2.5.3-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting SpeechRecognition (from LughaatNLP)\n",
            "  Downloading SpeechRecognition-3.10.4-py2.py3-none-any.whl.metadata (28 kB)\n",
            "Collecting pydub (from LughaatNLP)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gtts->LughaatNLP) (2.32.3)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gtts->LughaatNLP) (8.1.7)\n",
            "Collecting Levenshtein==0.26.0 (from python-Levenshtein->LughaatNLP)\n",
            "  Downloading levenshtein-0.26.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein==0.26.0->python-Levenshtein->LughaatNLP)\n",
            "  Downloading rapidfuzz-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->LughaatNLP) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->LughaatNLP) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition->LughaatNLP) (4.12.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->LughaatNLP) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->LughaatNLP) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow->LughaatNLP) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->LughaatNLP) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->LughaatNLP) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->LughaatNLP) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->LughaatNLP) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->LughaatNLP) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow->LughaatNLP) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow->LughaatNLP) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->LughaatNLP) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow->LughaatNLP) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->LughaatNLP) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->LughaatNLP) (2.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->LughaatNLP) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->LughaatNLP) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow->LughaatNLP) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->LughaatNLP) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->LughaatNLP) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow->LughaatNLP) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow->LughaatNLP) (13.8.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow->LughaatNLP) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow->LughaatNLP) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts->LughaatNLP) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts->LughaatNLP) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts->LughaatNLP) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts->LughaatNLP) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow->LughaatNLP) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow->LughaatNLP) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow->LughaatNLP) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow->LughaatNLP) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow->LughaatNLP) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow->LughaatNLP) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow->LughaatNLP) (0.1.2)\n",
            "Downloading LughaatNLP-1.0.6-py3-none-any.whl (69.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m69.8/69.8 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gTTS-2.5.3-py3-none-any.whl (29 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading python_Levenshtein-0.26.0-py3-none-any.whl (9.4 kB)\n",
            "Downloading levenshtein-0.26.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (162 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading SpeechRecognition-3.10.4-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, rapidfuzz, SpeechRecognition, Levenshtein, gtts, python-Levenshtein, LughaatNLP\n",
            "Successfully installed Levenshtein-0.26.0 LughaatNLP-1.0.6 SpeechRecognition-3.10.4 gtts-2.5.3 pydub-0.25.1 python-Levenshtein-0.26.0 rapidfuzz-3.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "Joq0PIhMQ__Z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "from LughaatNLP import LughaatNLP\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the dataset**"
      ],
      "metadata": {
        "id": "yloCq0x3UyPV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded=files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "6YgXk0z8c4yA",
        "outputId": "1108326b-3783-4ca3-a4d2-4fcbfcce4e45"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-aff21518-db7b-4d8f-a88f-c309d0e4a2e7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-aff21518-db7b-4d8f-a88f-c309d0e4a2e7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving urdu_sarcastic_dataset.csv to urdu_sarcastic_dataset (3).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the entire dataset\n",
        "df = pd.read_csv('urdu_sarcastic_dataset.csv')\n",
        "\n",
        "# Drop columns where the header is 'Unnamed:'\n",
        "data = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
        "\n",
        "# Display the first few rows of the sampled DataFrame\n",
        "data.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "Xv0Jt2kCY2KU",
        "outputId": "cc0c6890-8649-4d2c-901f-07355266d827"
      },
      "execution_count": 269,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                                                                                                                                                                        urdu_text  is_sarcastic\n",
              "0                                                                                                                                                                                                                     ğŸ¤£ğŸ˜‚ğŸ˜‚ ÛÙˆ Ù„ÛŒÙ†Û’ Ø¯Û’ Ù…ÛŒØ±ÛŒ Ø´Ø§Ø¯ÛŒ ÙØ³Ø§Ø¯Ù† Ù¹Ú¾ÛŒÚ© ÛÛ’ Ú©ÙˆØ¬ÛŒ Ù†ÛÛŒÚº Ú†Ø§ÛÛŒÛ’ ğŸ˜ğŸ˜ğŸ˜ğŸ¤£           1.0\n",
              "1                                                                                                                                                                                                                         Ú†Ù„ Ù…ÛÙ…Ø§Ù†ÙˆÚº Ù…ÛŒÚº Ú©Ú¾Ø§Ù†Ø§ Ø³Ø±Ùˆ Ú©Ø± Ú†Ú‘ÛŒÙ„ Ú†Ø§Ú†ÛŒ Ù†ÙˆÚº Ø¯Ø³Ø¯ÛŒ Ø¢Úº Ù…ÛŒÚºğŸ˜‚ğŸ˜‚           1.0\n",
              "2  Ú©Ø§Ù…Ø±Ø§Ù† Ø®Ø§Ù† Ø¢Ù¾Ú©ÛŒ Ø¯Ù† Ø¨Ú¾Ø±ÛŒÛ Ø²Ù…Û Ø¯Ø§Ø±ÛŒ Ù„Ú¯Ø§Ø¦ÛŒ Ú¯Ø¦ÛŒ Ø§Ù¾ÙˆØ²ÛŒØ´Ù† Ú©ÛŒ Ú©Ø±Ø¯Ø§Ø± Ú©Ø´ÛŒ Ø§ÙˆØ±Ø§Ø³ Ù¾Ø±Ø¨Ú¾ÙˆÙ†Ú©Ù†Ø§ÛÛ’Ø¢Ù¾ Ø®ÙˆØ´Ø§Ù…Ø¯Ú¯Ø±ÛŒ ÙˆÚ†Ø§Ù¾Ù„ÙˆØ³ÛŒ Ø³Û’Ø§ÙˆØ±Ú©ØªÙ†ÛŒ Ø¯ÙˆÙ„Øª Ú©Ù…Ø§Ù†Ø§Ú†Ø§ÛØªÛ’ÛÛŒÚº Ù…ÙˆÙ¹Ø±Ø³Ø§Ø¦ÛŒÚ©Ù„ Ø³Û’Ù¾ÛŒØ¬Ø§Ø±Ùˆ Ù¾Ø±Ø§ÚˆÙˆ ØªÚ© Ú©Û’Ø³ÙØ±Ù…ÛŒÚº Ø¶Ù…ÛŒØ±Ú©ÛŒ Ù„Ø§Ø´ Ø³Û’Ø§Ù¹Ú¾ØªÛŒ Ø¨Ø¯Ø¨ÙˆØ¢Ù¾ Ú©ÛŒ Ù†Ø§Ú© Ø¨Ù†Ø¯ Ù†ÛÛŒÚº Ú©Ø±ØªÛŒ ÛÛ’ ğŸ™Ù†ÙˆÙ¹ Ø¢Ù¾ Ø³Ø¨ Ø³Û’Ø§Ù„ØªØ¬Ø§Ú¯Ø²Ø§Ø±Ø´ ÛÛ’ÛÙ…ÛŒÚº Ø¨Ú¾ÛŒ ÙØ§Ù„ÙˆÚ©Ø±ÛŒÚº Ø´Ú©Ø±ÛŒÛ           0.0\n",
              "3                                                                                                                                                                                                                                                                    Ù†ÛÛŒÚº Ù¾Ø§Ø¦ÛŒÙ† ğŸ˜           0.0\n",
              "4                                                                                                                                                                                                                  `` Ù…Ø±Ø§Ø¯ Ø¹Ù„ÛŒ Ø´Ø§Û Ú©Û’ Ø¨Ú¾ÛŒØ³ Ù…ÛŒÚº ÚˆÛŒ Ø¬ÛŒ Ø¢Ø¦ÛŒ Ø§ÛŒØ³ Ø¢Ø¦ÛŒ ØªÚ¾Û’ '' Ø­Ø§Ù…Ø¯ Ù…ÛŒØ±ğŸ˜           1.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7bbe260a-57fe-414f-8e91-8a371f9b11a4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>urdu_text</th>\n",
              "      <th>is_sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ğŸ¤£ğŸ˜‚ğŸ˜‚ ÛÙˆ Ù„ÛŒÙ†Û’ Ø¯Û’ Ù…ÛŒØ±ÛŒ Ø´Ø§Ø¯ÛŒ ÙØ³Ø§Ø¯Ù† Ù¹Ú¾ÛŒÚ© ÛÛ’ Ú©ÙˆØ¬ÛŒ Ù†ÛÛŒÚº Ú†Ø§ÛÛŒÛ’ ğŸ˜ğŸ˜ğŸ˜ğŸ¤£</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ú†Ù„ Ù…ÛÙ…Ø§Ù†ÙˆÚº Ù…ÛŒÚº Ú©Ú¾Ø§Ù†Ø§ Ø³Ø±Ùˆ Ú©Ø± Ú†Ú‘ÛŒÙ„ Ú†Ø§Ú†ÛŒ Ù†ÙˆÚº Ø¯Ø³Ø¯ÛŒ Ø¢Úº Ù…ÛŒÚºğŸ˜‚ğŸ˜‚</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ú©Ø§Ù…Ø±Ø§Ù† Ø®Ø§Ù† Ø¢Ù¾Ú©ÛŒ Ø¯Ù† Ø¨Ú¾Ø±ÛŒÛ Ø²Ù…Û Ø¯Ø§Ø±ÛŒ Ù„Ú¯Ø§Ø¦ÛŒ Ú¯Ø¦ÛŒ Ø§Ù¾ÙˆØ²ÛŒØ´Ù† Ú©ÛŒ Ú©Ø±Ø¯Ø§Ø± Ú©Ø´ÛŒ Ø§ÙˆØ±Ø§Ø³ Ù¾Ø±Ø¨Ú¾ÙˆÙ†Ú©Ù†Ø§ÛÛ’Ø¢Ù¾ Ø®ÙˆØ´Ø§Ù…Ø¯Ú¯Ø±ÛŒ ÙˆÚ†Ø§Ù¾Ù„ÙˆØ³ÛŒ Ø³Û’Ø§ÙˆØ±Ú©ØªÙ†ÛŒ Ø¯ÙˆÙ„Øª Ú©Ù…Ø§Ù†Ø§Ú†Ø§ÛØªÛ’ÛÛŒÚº Ù…ÙˆÙ¹Ø±Ø³Ø§Ø¦ÛŒÚ©Ù„ Ø³Û’Ù¾ÛŒØ¬Ø§Ø±Ùˆ Ù¾Ø±Ø§ÚˆÙˆ ØªÚ© Ú©Û’Ø³ÙØ±Ù…ÛŒÚº Ø¶Ù…ÛŒØ±Ú©ÛŒ Ù„Ø§Ø´ Ø³Û’Ø§Ù¹Ú¾ØªÛŒ Ø¨Ø¯Ø¨ÙˆØ¢Ù¾ Ú©ÛŒ Ù†Ø§Ú© Ø¨Ù†Ø¯ Ù†ÛÛŒÚº Ú©Ø±ØªÛŒ ÛÛ’ ğŸ™Ù†ÙˆÙ¹ Ø¢Ù¾ Ø³Ø¨ Ø³Û’Ø§Ù„ØªØ¬Ø§Ú¯Ø²Ø§Ø±Ø´ ÛÛ’ÛÙ…ÛŒÚº Ø¨Ú¾ÛŒ ÙØ§Ù„ÙˆÚ©Ø±ÛŒÚº Ø´Ú©Ø±ÛŒÛ</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ù†ÛÛŒÚº Ù¾Ø§Ø¦ÛŒÙ† ğŸ˜</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>`` Ù…Ø±Ø§Ø¯ Ø¹Ù„ÛŒ Ø´Ø§Û Ú©Û’ Ø¨Ú¾ÛŒØ³ Ù…ÛŒÚº ÚˆÛŒ Ø¬ÛŒ Ø¢Ø¦ÛŒ Ø§ÛŒØ³ Ø¢Ø¦ÛŒ ØªÚ¾Û’ '' Ø­Ø§Ù…Ø¯ Ù…ÛŒØ±ğŸ˜</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7bbe260a-57fe-414f-8e91-8a371f9b11a4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7bbe260a-57fe-414f-8e91-8a371f9b11a4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7bbe260a-57fe-414f-8e91-8a371f9b11a4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c49700b9-de16-4fcd-bcf3-fa34749caff4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c49700b9-de16-4fcd-bcf3-fa34749caff4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c49700b9-de16-4fcd-bcf3-fa34749caff4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 20060,\n  \"fields\": [\n    {\n      \"column\": \"urdu_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15813,\n        \"samples\": [\n          \"\\u0635\\u0644\\u06cc \\u0627\\u0644\\u0644\\u06c1 \\u0639\\u0644\\u06cc\\u06c1 \\u0648\\u0627\\u0670\\u0644\\u06c1 \\u0648\\u0633\\u0644\\u0645\",\n          \"\\u0633\\u0686\\u06cc \\u0645\\u0632\\u06c1 \\u0622\\u06cc\\u0627 \\u06d4\\u06d4\\u06d4\\u0648\\u06cc\\u0633\\u06d2 \\u062d\\u06cc\\u062f\\u0631 \\u0628\\u06be\\u0627\\u0626\\u06cc \\u0628\\u06c1\\u062a \\u067e\\u06cc\\u0627\\u0631\\u06d2 \\u0627\\u0646\\u0633\\u0627\\u0646 \\u06c1\\u06cc\\u06ba \\u2764\",\n          \"\\ud83d\\ude02\\ud83e\\udd23\\ud83d\\ude02\\u0622\\u067e \\u0633\\u06d2 \\u0628\\u06c1\\u062a \\u0639\\u0631\\u0635\\u06c1 \\u067e\\u06c1\\u0644\\u06d2 \\u06a9\\u06c1\\u0627 \\u062a\\u06be\\u0627 \\u06a9\\u06c1 \\u0686\\u06be\\u0648\\u0644\\u06d2 \\u0641\\u0631\\u0648\\u0634 \\u0636\\u0645\\u06cc\\u0631 \\u0641\\u0631\\u0648\\u0634 \\u0627\\u0648\\u0631 \\u0633\\u067e\\u0644\\u0627\\u0626\\u06cc\\u0631 \\u062e\\u0648\\u062f \\u0633\\u0627\\u062e\\u062a\\u06c1 \\u0635\\u062d\\u0627\\u0641\\u06cc \\u06c1\\u06d2 \\u06cc\\u06c1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_sarcastic\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5000124954700192,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 269
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set pandas to display the full content of each row\n",
        "pd.set_option('display.max_colwidth', None)  # This ensures that column contents are displayed fully\n",
        "pd.set_option('display.max_rows', None)      # This shows all rows (if needed)\n",
        "pd.set_option('display.expand_frame_repr', False)  # Prevent line breaks"
      ],
      "metadata": {
        "id": "gE870IInPbAq"
      },
      "execution_count": 270,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize LughaatNLP instance\n",
        "urdu_text_processing = LughaatNLP()\n"
      ],
      "metadata": {
        "id": "Ie1ay1K3fzOx"
      },
      "execution_count": 271,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_data=data.copy()  #creating a copy so we can backup where needed"
      ],
      "metadata": {
        "id": "Cllrz4R4KEmr"
      },
      "execution_count": 272,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing**(Removing Stopword\n",
        "Punctuation, Emojis, and Hashtags\n",
        "Short Conversations etc)"
      ],
      "metadata": {
        "id": "spS4eXIAUWse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocessing\n",
        "# Define a function to apply the preprocessing steps\n",
        "def preprocess_text(text):\n",
        "    # Ensure the input is a string before processing\n",
        "    if isinstance(text, str):\n",
        "\n",
        "        # Step 1: Remove diacritics\n",
        "        text = urdu_text_processing.remove_diacritics(text)\n",
        "\n",
        "        # Step 2: Remove punctuation and extra spaces\n",
        "        text = urdu_text_processing.punctuations_space(text)\n",
        "\n",
        "        # Step 3: Remove URLs\n",
        "        text = urdu_text_processing.remove_urls(text)\n",
        "\n",
        "        # Step 4: Remove emojis (assuming emojis are considered special characters in Urdu)\n",
        "        text = urdu_text_processing.remove_special_characters(text)\n",
        "\n",
        "        # Step 5: Remove hashtags\n",
        "        text = text.replace('#', '')\n",
        "\n",
        "        # Step 6: Remove short conversational phrases (you may set a threshold like < 3 words)\n",
        "        if len(text.split()) < 3:  # Remove if too short (less than 3 words)\n",
        "            return ''\n",
        "\n",
        "        return text\n",
        "    return text  # If it's not a string, return as is"
      ],
      "metadata": {
        "id": "kCwonrtbZ1uM"
      },
      "execution_count": 273,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "urdu_stopwords = [\n",
        "    \"Ø¢\", \"Ø¢Ø¦ÛŒ\", \"Ø¢Ø¦ÛŒÚº\", \"Ø¢Ø¦Û’\", \"Ø¢ØªØ§\", \"Ø¢ØªÛŒ\", \"Ø¢ØªÛ’\", \"Ø¢Ø¯Ø§Ø¨\", \"Ø¢Ø¯Ú¾\", \"Ø¢Ø¯Ú¾Ø§\", \"Ø¢Ø¯Ú¾ÛŒ\", \"Ø¢Ø¯Ú¾Û’\", \"Ø¢Ø³\", \"Ø¢Ù…Ø¯ÛŒØ¯\", \"Ø¢Ù†Ø§\", \"Ø¢Ù†Ø³Û\",\n",
        "    \"Ø¢Ù†ÛŒ\", \"Ø¢Ù†Û’\", \"Ø¢Ù¾\", \"Ø¢Ú¯Û’\", \"Ø¢Û\", \"Ø¢ÛØ§\", \"Ø¢ÛŒØ§\", \"Ø§Ø¨\", \"Ø§Ø¨Ú¾ÛŒ\", \"Ø§Ø¨Û’\", \"Ø§ØªÙˆØ§Ø±\", \"Ø§Ø±Ø¨\", \"Ø§Ø±Ø¨ÙˆÛŒÚº\", \"Ø§Ø±Û’\", \"Ø§Ø³\", \"Ø§Ø³Ú©Ø§\",\n",
        "    \"Ø§Ø³Ú©ÛŒ\", \"Ø§Ø³Ú©Û’\", \"Ø§Ø³ÛŒ\", \"Ø§Ø³Û’\", \"Ø§Ù\", \"Ø§ÙÙˆÛ\", \"Ø§Ù„Ø§ÙˆÙ„\", \"Ø§Ù„Ø¨ØªÛ\", \"Ø§Ù„Ø«Ø§Ù†ÛŒ\", \"Ø§Ù„Ø­Ø±Ø§Ù…\", \"Ø§Ù„Ø³Ù„Ø§Ù…\", \"Ø§Ù„Ù\", \"Ø§Ù„Ù…Ú©Ø±Ù…\",\n",
        "    \"Ø§Ù†\", \"Ø§Ù†Ø¯Ø±\", \"Ø§Ù†Ú©Ø§\", \"Ø§Ù†Ú©ÛŒ\", \"Ø§Ù†Ú©Û’\", \"Ø§Ù†ÛÙˆÚº\", \"Ø§Ù†ÛÛŒ\", \"Ø§Ù†ÛÛŒÚº\", \"Ø§ÙˆØ¦Û’\", \"Ø§ÙˆØ±\", \"Ø§ÙˆÙ¾Ø±\", \"Ø§ÙˆÛÙˆ\", \"Ø§Ù¾\", \"Ø§Ù¾Ù†Ø§\", \"Ø§Ù¾Ù†ÙˆÚº\",\n",
        "    \"Ø§Ù¾Ù†ÛŒ\", \"Ø§Ù¾Ù†Û’\", \"Ø§Ù¾Ù†Û’Ø¢Ù¾\", \"Ø§Ú©Ø¨Ø±\", \"Ø§Ú©Ø«Ø±\", \"Ø§Ú¯Ø±\", \"Ø§Ú¯Ø±Ú†Û\", \"Ø§Ú¯Ø³Øª\", \"Ø§ÛØ§ÛØ§\", \"Ø§ÛŒØ³Ø§\", \"Ø§ÛŒØ³ÛŒ\", \"Ø§ÛŒØ³Û’\", \"Ø§ÛŒÚ©\", \"Ø¨Ø§Ø¦ÛŒÚº\",\n",
        "    \"Ø¨Ø§Ø±\", \"Ø¨Ø§Ø±Û’\", \"Ø¨Ø§Ù„Ú©Ù„\", \"Ø¨Û’\", \"Ø¨ØºÛŒØ±\", \"Ø¨Ù„Ú©Û\", \"Ø¨Ù†\", \"Ø¨Ù†Ø§\", \"Ø¨Ù†Ø§Ø¤\", \"Ø¨Ù†Ø¯\", \"Ø¨Ú‘ÛŒ\", \"Ø¨Ú¾Ø±\", \"Ø¨Ú¾Ø±ÛŒÚº\", \"Ø¨Ú¾ÛŒ\", \"Ø¨ÛØ§Ø±\",\n",
        "    \"Ø¨ÛØª\", \"Ø¨ÛØªØ±\", \"Ø¨ÛŒÚ¯Ù…\", \"ØªØ§Ú©Û\", \"ØªØ§ÛÙ…\", \"ØªØ¨\", \"ØªØ¬Ú¾\", \"ØªØ¬Ú¾Ú¾ÛŒ\", \"ØªØ¬Ú¾Û’\", \"ØªØ±Ø§\", \"ØªØ±ÛŒ\", \"ØªÙ„Ú©\", \"ØªÙ…\", \"ØªÙ…Ø§Ù…\", \"ØªÙ…ÛØ§Ø±Ø§\",\n",
        "    \"ØªÙ…ÛØ§Ø±ÙˆÚº\", \"ØªÙ…ÛØ§Ø±ÛŒ\", \"ØªÙ…ÛØ§Ø±Û’\", \"ØªÙ…ÛÛŒÚº\", \"ØªÙˆ\", \"ØªÚ©\", \"ØªÚ¾Ø§\", \"ØªÚ¾ÛŒ\", \"ØªÚ¾ÛŒÚº\", \"ØªÚ¾Û’\", \"ØªÛØ§Ø¦ÛŒ\", \"ØªÛŒØ±Ø§\", \"ØªÛŒØ±ÛŒ\", \"ØªÛŒØ±Û’\",\n",
        "    \"ØªÛŒÙ†\", \"Ø¬Ø§\", \"Ø¬Ø§Ø¤\", \"Ø¬Ø§Ø¦ÛŒÚº\", \"Ø¬Ø§Ø¦Û’\", \"Ø¬Ø§ØªØ§\", \"Ø¬Ø§ØªÛŒ\", \"Ø¬Ø§ØªÛ’\", \"Ø¬Ø§Ù†ÛŒ\", \"Ø¬Ø§Ù†Û’\", \"Ø¬Ø¨\", \"Ø¬Ø¨Ú©Û\", \"Ø¬Ø¯Ú¾Ø±\", \"Ø¬Ø³\", \"Ø¬Ø³Û’\",\n",
        "    \"Ø¬Ù†\", \"Ø¬Ù†Ø§Ø¨\", \"Ø¬Ù†ÛÙˆÚº\", \"Ø¬Ù†ÛÛŒÚº\", \"Ø¬Ùˆ\", \"Ú©ÛØ§Úº\", \"Ú©ÛÛ\", \"Ú©ÛÛŒ\", \"Ú©ÛÛŒÚº\", \"Ú©ÛÛ’\", \"Ú©ÛŒ\", \"Ú©ÛŒØ§\", \"Ú©ÛŒØ³Ø§\", \"Ú©ÛŒØ³Û’\", \"Ú©ÛŒÙˆÙ†Ú©Ø±\",\n",
        "    \"Ú©ÛŒÙˆÚº\", \"Ú©ÛŒÛ’\", \"Ú©Û’\", \"Ú¯Ø¦ÛŒ\", \"Ú¯Ø¦Û’\", \"Ú¯Ø§\", \"Ú¯Ø±Ù…Ø§\", \"Ú¯Ø±Ù…ÛŒ\", \"Ú¯Ù†Ø§\", \"Ú¯Ùˆ\", \"Ú¯ÙˆÛŒØ§\", \"Ú¯Ú¾Ù†Ù¹Ø§\", \"Ú¯Ú¾Ù†Ù¹ÙˆÚº\", \"Ú¯Ú¾Ù†Ù¹Û’\", \"Ú¯ÛŒ\",\n",
        "    \"Ú¯ÛŒØ§\", \"ÛØ§Ø¦ÛŒÚº\", \"ÛØ§Ø¦Û’\", \"ÛØ§Ú‘\", \"ÛØ§Úº\", \"ÛØ±\", \"ÛØ±Ú†Ù†Ø¯\", \"ÛØ±Ú¯Ø²\", \"ÛØ²Ø§Ø±\", \"ÛÙØªÛ\", \"ÛÙ…\", \"ÛÙ…Ø§Ø±Ø§\", \"ÛÙ…Ø§Ø±ÛŒ\", \"ÛÙ…Ø§Ø±Û’\", \"ÛÙ…ÛŒ\",\n",
        "    \"ÛÙ…ÛŒÚº\", \"ÛÙˆ\", \"ÛÙˆØ¦ÛŒ\", \"ÛÙˆØ¦ÛŒÚº\", \"ÛÙˆØ¦Û’\", \"ÛÙˆØ§\", \"ÛÙˆØ¨ÛÙˆ\", \"ÛÙˆØªØ§\", \"ÛÙˆØªÛŒ\", \"ÛÙˆØªÛŒÚº\", \"ÛÙˆØªÛ’\", \"ÛÙˆÙ†Ø§\", \"ÛÙˆÙ†Ú¯Û’\", \"ÛÙˆÙ†ÛŒ\",\n",
        "    \"ÛÙˆÙ†Û’\", \"ÛÙˆÚº\", \"ÛÛŒ\", \"ÛÛŒÙ„Ùˆ\", \"ÛÛŒÚº\", \"ÛÛ’\", \"ÛŒØ§\", \"ÛŒØ§Øª\", \"ÛŒØ¹Ù†ÛŒ\", \"ÛŒÚ©\", \"ÛŒÛ\", \"ÛŒÛØ§Úº\", \"ÛŒÛÛŒ\", \"ÛŒÛÛŒÚº\", \"Ú©Ø±\",\n",
        "    \"Ù…ÛŒØ±ÛŒ\", \"Ù…ÛŒÚº\",\n",
        "    \"Ú©Ùˆ\", \"Ø³Û’\", \"Ú©Ø§\", \"Ù†Û’\"\n",
        "]"
      ],
      "metadata": {
        "id": "6tm1VCbs9Ham"
      },
      "execution_count": 274,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to remove stop words\n",
        "def remove_stop_words(text):\n",
        "    words = text.split()  # Split the text into words\n",
        "    cleaned_words = [word for word in words if word not in urdu_stopwords]  # Filter out stop words\n",
        "    return ' '.join(cleaned_words)  # Join the cleaned words back into a string\n"
      ],
      "metadata": {
        "id": "KN1BxXx49Dmn"
      },
      "execution_count": 275,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#drop rows if data missing or empty string\n",
        "data = data.dropna(subset=['urdu_text']) # for missing\n",
        "data['urdu_text'] = data['urdu_text'].str.strip()  # Remove leading and trailing whitespace\n",
        "data = data[data['urdu_text'] != '']  # Drop empty strings\n",
        "\n",
        "# Apply the preprocessing function to the 'urdu_text' column\n",
        "data['urdu_text'] = data['urdu_text'].apply(preprocess_text)\n",
        "\n",
        "#remove stopwords now\n",
        "data['clean_text'] = data['urdu_text'].apply(remove_stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ll5IfyujqgB",
        "outputId": "fa7490e9-37ad-432f-abb9-0f8d94e228ce",
        "collapsed": true
      },
      "execution_count": 276,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-276-4a2b7a13fa63>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['urdu_text'] = data['urdu_text'].str.strip()  # Remove leading and trailing whitespace\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clearing after the preprocessing**"
      ],
      "metadata": {
        "id": "hsWToH-pUD3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Strip whitespace and drop empty strings\n",
        "data['clean_text'] = data['clean_text'].str.strip()  # Remove leading and trailing whitespace\n",
        "data = data[data['clean_text'] != '']  # Drop empty strings\n",
        "data['clean_text'].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "tCfQbxQKmnnB",
        "outputId": "b0ec75a5-23d3-4d98-bafd-5e429d8f22f8"
      },
      "execution_count": 277,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                                                                                                                                                                                               Ù„ÛŒÙ†Û’ Ø¯Û’ Ø´Ø§Ø¯ÛŒ ÙØ³Ø§Ø¯Ù† Ù¹Ú¾ÛŒÚ© Ú©ÙˆØ¬ÛŒ Ù†ÛÛŒÚº Ú†Ø§ÛÛŒÛ’\n",
              "1                                                                                                                                                                                                            Ú†Ù„ Ù…ÛÙ…Ø§Ù†ÙˆÚº Ú©Ú¾Ø§Ù†Ø§ Ø³Ø±Ùˆ Ú†Ú‘ÛŒÙ„ Ú†Ø§Ú†ÛŒ Ù†ÙˆÚº Ø¯Ø³Ø¯ÛŒ Ø§Úº\n",
              "2    Ú©Ø§Ù…Ø±Ø§Ù† Ø®Ø§Ù† Ø§Ù¾Ú©ÛŒ Ø¯Ù† Ø¨Ú¾Ø±ÛŒÛ Ø²Ù…Û Ø¯Ø§Ø±ÛŒ Ù„Ú¯Ø§Ø¦ÛŒ Ø§Ù¾ÙˆØ²ÛŒØ´Ù† Ú©Ø±Ø¯Ø§Ø± Ú©Ø´ÛŒ Ø§ÙˆØ±Ø§Ø³ Ù¾Ø±Ø¨Ú¾ÙˆÙ†Ú©Ù†Ø§ÛÛ’Ø§Ù¾ Ø®ÙˆØ´Ø§Ù…Ø¯Ú¯Ø±ÛŒ ÙˆÚ†Ø§Ù¾Ù„ÙˆØ³ÛŒ Ø³Û’Ø§ÙˆØ±Ú©ØªÙ†ÛŒ Ø¯ÙˆÙ„Øª Ú©Ù…Ø§Ù†Ø§Ú†Ø§ÛØªÛ’ÛÛŒÚº Ù…ÙˆÙ¹Ø±Ø³Ø§Ø¦ÛŒÚ©Ù„ Ø³Û’Ù¾ÛŒØ¬Ø§Ø±Ùˆ Ù¾Ø±Ø§ÚˆÙˆ Ú©Û’Ø³ÙØ±Ù…ÛŒÚº Ø¶Ù…ÛŒØ±Ú©ÛŒ Ù„Ø§Ø´ Ø³Û’Ø§Ù¹Ú¾ØªÛŒ Ø¨Ø¯Ø¨ÙˆØ§Ù¾ Ù†Ø§Ú© Ù†ÛÛŒÚº Ú©Ø±ØªÛŒ Ù†ÙˆÙ¹ Ø³Ø¨ Ø³Û’Ø§Ù„ØªØ¬Ø§Ú¯Ø²Ø§Ø±Ø´ ÛÛ’ÛÙ…ÛŒÚº ÙØ§Ù„ÙˆÚ©Ø±ÛŒÚº Ø´Ú©Ø±ÛŒÛ\n",
              "4                                                                                                                                                                                                          Ù…Ø±Ø§Ø¯ Ø¹Ù„ÛŒ Ø´Ø§Û Ø¨Ú¾ÛŒØ³ ÚˆÛŒ Ø¬ÛŒ Ø§Ø¦ÛŒ Ø§ÛŒØ³ Ø§Ø¦ÛŒ Ø­Ø§Ù…Ø¯ Ù…ÛŒØ±\n",
              "5                                                                                                                                                                                                                               Ù‚Ø§Ø¨Ù„ Ø§Ø¹ØªØ¨Ø§Ø± Ù‚Ø§ØªÙ„ Ø§Ø¹ØªØ¨Ø§Ø±\n",
              "Name: clean_text, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ù„ÛŒÙ†Û’ Ø¯Û’ Ø´Ø§Ø¯ÛŒ ÙØ³Ø§Ø¯Ù† Ù¹Ú¾ÛŒÚ© Ú©ÙˆØ¬ÛŒ Ù†ÛÛŒÚº Ú†Ø§ÛÛŒÛ’</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ú†Ù„ Ù…ÛÙ…Ø§Ù†ÙˆÚº Ú©Ú¾Ø§Ù†Ø§ Ø³Ø±Ùˆ Ú†Ú‘ÛŒÙ„ Ú†Ø§Ú†ÛŒ Ù†ÙˆÚº Ø¯Ø³Ø¯ÛŒ Ø§Úº</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ú©Ø§Ù…Ø±Ø§Ù† Ø®Ø§Ù† Ø§Ù¾Ú©ÛŒ Ø¯Ù† Ø¨Ú¾Ø±ÛŒÛ Ø²Ù…Û Ø¯Ø§Ø±ÛŒ Ù„Ú¯Ø§Ø¦ÛŒ Ø§Ù¾ÙˆØ²ÛŒØ´Ù† Ú©Ø±Ø¯Ø§Ø± Ú©Ø´ÛŒ Ø§ÙˆØ±Ø§Ø³ Ù¾Ø±Ø¨Ú¾ÙˆÙ†Ú©Ù†Ø§ÛÛ’Ø§Ù¾ Ø®ÙˆØ´Ø§Ù…Ø¯Ú¯Ø±ÛŒ ÙˆÚ†Ø§Ù¾Ù„ÙˆØ³ÛŒ Ø³Û’Ø§ÙˆØ±Ú©ØªÙ†ÛŒ Ø¯ÙˆÙ„Øª Ú©Ù…Ø§Ù†Ø§Ú†Ø§ÛØªÛ’ÛÛŒÚº Ù…ÙˆÙ¹Ø±Ø³Ø§Ø¦ÛŒÚ©Ù„ Ø³Û’Ù¾ÛŒØ¬Ø§Ø±Ùˆ Ù¾Ø±Ø§ÚˆÙˆ Ú©Û’Ø³ÙØ±Ù…ÛŒÚº Ø¶Ù…ÛŒØ±Ú©ÛŒ Ù„Ø§Ø´ Ø³Û’Ø§Ù¹Ú¾ØªÛŒ Ø¨Ø¯Ø¨ÙˆØ§Ù¾ Ù†Ø§Ú© Ù†ÛÛŒÚº Ú©Ø±ØªÛŒ Ù†ÙˆÙ¹ Ø³Ø¨ Ø³Û’Ø§Ù„ØªØ¬Ø§Ú¯Ø²Ø§Ø±Ø´ ÛÛ’ÛÙ…ÛŒÚº ÙØ§Ù„ÙˆÚ©Ø±ÛŒÚº Ø´Ú©Ø±ÛŒÛ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ù…Ø±Ø§Ø¯ Ø¹Ù„ÛŒ Ø´Ø§Û Ø¨Ú¾ÛŒØ³ ÚˆÛŒ Ø¬ÛŒ Ø§Ø¦ÛŒ Ø§ÛŒØ³ Ø§Ø¦ÛŒ Ø­Ø§Ù…Ø¯ Ù…ÛŒØ±</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Ù‚Ø§Ø¨Ù„ Ø§Ø¹ØªØ¨Ø§Ø± Ù‚Ø§ØªÙ„ Ø§Ø¹ØªØ¨Ø§Ø±</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 277
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stemming**"
      ],
      "metadata": {
        "id": "k2DoHbD8ULh8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#stemming\n",
        "data['stemmed_text'] = data['clean_text'].apply(urdu_text_processing.urdu_stemmer)"
      ],
      "metadata": {
        "id": "zAWLjZVsNffK"
      },
      "execution_count": 278,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['stemmed_text'].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "PhJeUCAaNr-K",
        "outputId": "7fb964bc-b766-4b2c-c20f-eacbeb1c4347"
      },
      "execution_count": 279,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                                                                                                                                                                                           Ù„ÛŒÙ†Û Ø¯Û Ø´Ø§Ø¯ÛŒ ÙØ³Ø§Ø¯Ù† Ù¹Ú¾ÛŒÚ© Ú©ÙˆØ¬ÛŒ Ù†ÛØ§ Ú†Ø§ÛÛŒÛ\n",
              "1                                                                                                                                                                                                         Ú†Ù„ Ù…ÛÙ…Ø§Ù†Ø§ Ú©Ú¾Ø§Ù†Ø§ Ø³Ø±Ùˆ Ú†Ú‘ÛŒÙ„ Ú†Ø§Ú†ÛŒ Ù†Ø§ Ø¯Ø³Ø¯ÛŒ Ø§Úº\n",
              "2    Ú©Ø§Ù…Ø±Ø§Ù† Ø®Ø§Ù† Ø§Ù¾Ú©ÛŒ Ø¯Ù† Ø¨Ú¾Ø±ÛŒÛ Ø²Ù…Û Ø¯Ø§Ø±ÛŒ Ù„Ú¯Ø§Ø¦ÛŒ Ø§Ù¾ÙˆØ²ÛŒØ´Ù† Ú©Ø±Ø¯Ø§Ø± Ú©Ø´ÛŒ Ø§ÙˆØ±Ø§Ø³ Ù¾Ø±Ø¨Ú¾ÙˆÙ†Ú©Ù†Ø§ÛÛ’Ø§Ù¾ Ø®ÙˆØ´Ø§Ù…Ø¯Ú¯Ø±ÛŒ ÙˆÚ†Ø§Ù¾Ù„ÙˆØ³ÛŒ Ø³Û’Ø§ÙˆØ±Ú©ØªÙ†ÛŒ Ø¯ÙˆÙ„Øª Ú©Ù…Ø§Ù†Ø§Ú†Ø§ÛØªÛ’ÛØ§ Ù…ÙˆÙ¹Ø±Ø³Ø§Ø¦ÛŒÚ©Ù„ Ø³Û’Ù¾ÛŒØ¬Ø§Ø±Ùˆ Ù¾Ø±Ø§ÚˆÙˆ Ú©Û’Ø³ÙØ±Ù…Ø§ Ø¶Ù…ÛŒØ±Ú©ÛŒ Ù„Ø§Ø´ Ø³Û’Ø§Ù¹Ú¾ØªÛŒ Ø¨Ø¯Ø¨ÙˆØ§Ù¾ Ù†Ø§Ú© Ù†ÛØ§ Ú©Ø±ØªÛŒ Ù†ÙˆÙ¹ Ø³Ø¨ Ø³Û’Ø§Ù„ØªØ¬Ø§Ú¯Ø²Ø§Ø±Ø´ ÛÛ’ÛÙ…Ø§ ÙØ§Ù„ÙˆÚ©Ø±Ø§ Ø´Ú©Ø±ÛŒÛ\n",
              "4                                                                                                                                                                                                     Ù…Ø±Ø§Ø¯ Ø¹Ù„ÛŒ Ø´Ø§Û Ø¨Ú¾ÛŒØ³ ÚˆÛŒ Ø¬ÛŒ Ø§Ø¦ÛŒ Ø§ÛŒØ³ Ø§Ø¦ÛŒ Ø­Ø§Ù…Ø¯ Ù…ÛŒØ±\n",
              "5                                                                                                                                                                                                                            Ù‚Ø§Ø¨Ù„ Ø§Ø¹ØªØ¨Ø± Ù‚Ø§ØªÙ„ Ø§Ø¹ØªØ¨Ø±\n",
              "Name: stemmed_text, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stemmed_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ù„ÛŒÙ†Û Ø¯Û Ø´Ø§Ø¯ÛŒ ÙØ³Ø§Ø¯Ù† Ù¹Ú¾ÛŒÚ© Ú©ÙˆØ¬ÛŒ Ù†ÛØ§ Ú†Ø§ÛÛŒÛ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ú†Ù„ Ù…ÛÙ…Ø§Ù†Ø§ Ú©Ú¾Ø§Ù†Ø§ Ø³Ø±Ùˆ Ú†Ú‘ÛŒÙ„ Ú†Ø§Ú†ÛŒ Ù†Ø§ Ø¯Ø³Ø¯ÛŒ Ø§Úº</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ú©Ø§Ù…Ø±Ø§Ù† Ø®Ø§Ù† Ø§Ù¾Ú©ÛŒ Ø¯Ù† Ø¨Ú¾Ø±ÛŒÛ Ø²Ù…Û Ø¯Ø§Ø±ÛŒ Ù„Ú¯Ø§Ø¦ÛŒ Ø§Ù¾ÙˆØ²ÛŒØ´Ù† Ú©Ø±Ø¯Ø§Ø± Ú©Ø´ÛŒ Ø§ÙˆØ±Ø§Ø³ Ù¾Ø±Ø¨Ú¾ÙˆÙ†Ú©Ù†Ø§ÛÛ’Ø§Ù¾ Ø®ÙˆØ´Ø§Ù…Ø¯Ú¯Ø±ÛŒ ÙˆÚ†Ø§Ù¾Ù„ÙˆØ³ÛŒ Ø³Û’Ø§ÙˆØ±Ú©ØªÙ†ÛŒ Ø¯ÙˆÙ„Øª Ú©Ù…Ø§Ù†Ø§Ú†Ø§ÛØªÛ’ÛØ§ Ù…ÙˆÙ¹Ø±Ø³Ø§Ø¦ÛŒÚ©Ù„ Ø³Û’Ù¾ÛŒØ¬Ø§Ø±Ùˆ Ù¾Ø±Ø§ÚˆÙˆ Ú©Û’Ø³ÙØ±Ù…Ø§ Ø¶Ù…ÛŒØ±Ú©ÛŒ Ù„Ø§Ø´ Ø³Û’Ø§Ù¹Ú¾ØªÛŒ Ø¨Ø¯Ø¨ÙˆØ§Ù¾ Ù†Ø§Ú© Ù†ÛØ§ Ú©Ø±ØªÛŒ Ù†ÙˆÙ¹ Ø³Ø¨ Ø³Û’Ø§Ù„ØªØ¬Ø§Ú¯Ø²Ø§Ø±Ø´ ÛÛ’ÛÙ…Ø§ ÙØ§Ù„ÙˆÚ©Ø±Ø§ Ø´Ú©Ø±ÛŒÛ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ù…Ø±Ø§Ø¯ Ø¹Ù„ÛŒ Ø´Ø§Û Ø¨Ú¾ÛŒØ³ ÚˆÛŒ Ø¬ÛŒ Ø§Ø¦ÛŒ Ø§ÛŒØ³ Ø§Ø¦ÛŒ Ø­Ø§Ù…Ø¯ Ù…ÛŒØ±</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Ù‚Ø§Ø¨Ù„ Ø§Ø¹ØªØ¨Ø± Ù‚Ø§ØªÙ„ Ø§Ø¹ØªØ¨Ø±</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 279
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lemmatization**"
      ],
      "metadata": {
        "id": "zqQQaT_iURDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#lemmatization\n",
        "data['lemmatized_text'] = data['clean_text'].apply(urdu_text_processing.lemmatize_sentence)"
      ],
      "metadata": {
        "id": "rPF3YleATjnt"
      },
      "execution_count": 280,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['lemmatized_text'].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "VdIxBJRpT20A",
        "outputId": "f42dbf3b-ab65-4309-99bd-0915ba7c0c90"
      },
      "execution_count": 281,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                                                                                                                                                                                            Ù„ÛŒÙ†Ø§ Ø¯ÛŒÙ†Ø§ Ø´Ø§Ø¯ÛŒ ÙØ³Ø§Ø¯Ù† Ù¹Ú¾ÛŒÚ© Ú©ÙˆØ¬ÛŒ Ù†ÛÛŒÚº Ú†Ø§ÛÙ†Ø§\n",
              "1                                                                                                                                                                                                             Ú†Ù„Ù†Ø§ Ù…ÛÙ…Ø§Ù† Ú©Ú¾Ø§ Ø³Ø±Ø§ Ú†Ú‘ÛŒÙ„ Ú†Ø§Ú†ÛŒ Ù†ÙˆÚº Ø¯Ø³Ø¯ÛŒ Ø§Úº\n",
              "2    Ú©Ø§Ù…Ø±Ø§Ù† Ø®Ø§Ù† Ø§Ù¾Ú©ÛŒ Ø¯Ù† Ø¨Ú¾Ø±ÛŒÛ Ø²Ù…Û Ø¯Ø§Ø±ÛŒ Ù„Ú¯Ù†Ø§ Ø§Ù¾ÙˆØ²ÛŒØ´Ù† Ú©Ø±Ø¯Ø§Ø± Ú©Ø´ÛŒ Ø§ÙˆØ±Ø§Ø³ Ù¾Ø±Ø¨Ú¾ÙˆÙ†Ú©Ù†Ø§ÛÛ’Ø§Ù¾ Ø®ÙˆØ´Ø§Ù…Ø¯Ú¯Ø±ÛŒ ÙˆÚ†Ø§Ù¾Ù„ÙˆØ³ÛŒ Ø³Û’Ø§ÙˆØ±Ú©ØªÙ†ÛŒ Ø¯ÙˆÙ„Øª Ú©Ù…Ø§Ù†Ø§Ú†Ø§ÛØªÛ’ÛÛŒÚº Ù…ÙˆÙ¹Ø±Ø³Ø§Ø¦ÛŒÚ©Ù„ Ø³Û’Ù¾ÛŒØ¬Ø§Ø±Ùˆ Ù¾Ø±Ø§ÚˆÙˆ Ú©Û’Ø³ÙØ±Ù…ÛŒÚº Ø¶Ù…ÛŒØ±Ú©ÛŒ Ù„Ø§Ø´ Ø³Û’Ø§Ù¹Ú¾ØªÛŒ Ø¨Ø¯Ø¨ÙˆØ§Ù¾ Ù†Ø§Ú© Ù†ÛÛŒÚº Ú©Ø±Ù†Ø§ Ù†ÙˆÙ¹ Ø³Ø¨ Ø³Û’Ø§Ù„ØªØ¬Ø§Ú¯Ø²Ø§Ø±Ø´ ÛÛ’ÛÙ…ÛŒÚº ÙØ§Ù„ÙˆÚ©Ø±ÛŒÚº Ø´Ú©Ø±ÛŒÛ\n",
              "4                                                                                                                                                                                                       Ù…Ø±Ø§Ø¯ Ø¹Ù„ÛŒ Ø´Ø§Û Ø¨Ú¾ÛŒØ³ ÚˆÛŒ Ø¬ÛŒÙ†Ø§ Ø§Ø¦ÛŒ Ø§ÛŒØ³ Ø§Ø¦ÛŒ Ø­Ø§Ù…Ø¯ Ù…ÛŒØ±\n",
              "5                                                                                                                                                                                                                              Ù‚Ø§Ø¨Ù„ Ø§Ø¹ØªØ¨Ø§Ø± Ù‚Ø§ØªÙ„ Ø§Ø¹ØªØ¨Ø§Ø±\n",
              "Name: lemmatized_text, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lemmatized_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ù„ÛŒÙ†Ø§ Ø¯ÛŒÙ†Ø§ Ø´Ø§Ø¯ÛŒ ÙØ³Ø§Ø¯Ù† Ù¹Ú¾ÛŒÚ© Ú©ÙˆØ¬ÛŒ Ù†ÛÛŒÚº Ú†Ø§ÛÙ†Ø§</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ú†Ù„Ù†Ø§ Ù…ÛÙ…Ø§Ù† Ú©Ú¾Ø§ Ø³Ø±Ø§ Ú†Ú‘ÛŒÙ„ Ú†Ø§Ú†ÛŒ Ù†ÙˆÚº Ø¯Ø³Ø¯ÛŒ Ø§Úº</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ú©Ø§Ù…Ø±Ø§Ù† Ø®Ø§Ù† Ø§Ù¾Ú©ÛŒ Ø¯Ù† Ø¨Ú¾Ø±ÛŒÛ Ø²Ù…Û Ø¯Ø§Ø±ÛŒ Ù„Ú¯Ù†Ø§ Ø§Ù¾ÙˆØ²ÛŒØ´Ù† Ú©Ø±Ø¯Ø§Ø± Ú©Ø´ÛŒ Ø§ÙˆØ±Ø§Ø³ Ù¾Ø±Ø¨Ú¾ÙˆÙ†Ú©Ù†Ø§ÛÛ’Ø§Ù¾ Ø®ÙˆØ´Ø§Ù…Ø¯Ú¯Ø±ÛŒ ÙˆÚ†Ø§Ù¾Ù„ÙˆØ³ÛŒ Ø³Û’Ø§ÙˆØ±Ú©ØªÙ†ÛŒ Ø¯ÙˆÙ„Øª Ú©Ù…Ø§Ù†Ø§Ú†Ø§ÛØªÛ’ÛÛŒÚº Ù…ÙˆÙ¹Ø±Ø³Ø§Ø¦ÛŒÚ©Ù„ Ø³Û’Ù¾ÛŒØ¬Ø§Ø±Ùˆ Ù¾Ø±Ø§ÚˆÙˆ Ú©Û’Ø³ÙØ±Ù…ÛŒÚº Ø¶Ù…ÛŒØ±Ú©ÛŒ Ù„Ø§Ø´ Ø³Û’Ø§Ù¹Ú¾ØªÛŒ Ø¨Ø¯Ø¨ÙˆØ§Ù¾ Ù†Ø§Ú© Ù†ÛÛŒÚº Ú©Ø±Ù†Ø§ Ù†ÙˆÙ¹ Ø³Ø¨ Ø³Û’Ø§Ù„ØªØ¬Ø§Ú¯Ø²Ø§Ø±Ø´ ÛÛ’ÛÙ…ÛŒÚº ÙØ§Ù„ÙˆÚ©Ø±ÛŒÚº Ø´Ú©Ø±ÛŒÛ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ù…Ø±Ø§Ø¯ Ø¹Ù„ÛŒ Ø´Ø§Û Ø¨Ú¾ÛŒØ³ ÚˆÛŒ Ø¬ÛŒÙ†Ø§ Ø§Ø¦ÛŒ Ø§ÛŒØ³ Ø§Ø¦ÛŒ Ø­Ø§Ù…Ø¯ Ù…ÛŒØ±</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Ù‚Ø§Ø¨Ù„ Ø§Ø¹ØªØ¨Ø§Ø± Ù‚Ø§ØªÙ„ Ø§Ø¹ØªØ¨Ø§Ø±</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 281
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Extraction from Urdu**"
      ],
      "metadata": {
        "id": "TUfBvsVMWBrn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenization"
      ],
      "metadata": {
        "id": "rY4Ouee8WWzL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['tokenized_text'] = data['clean_text'].apply(urdu_text_processing.urdu_tokenize)"
      ],
      "metadata": {
        "id": "SfAkNbGdVQoY"
      },
      "execution_count": 282,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['tokenized_text'].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "zHKNFjoiWo4J",
        "outputId": "e6e1dd2c-0ce0-43a9-be77-3467bc6e77c0"
      },
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                                                                                                                                                                                                                          [Ù„ÛŒÙ†Û’, Ø¯Û’, Ø´Ø§Ø¯ÛŒ, ÙØ³Ø§Ø¯Ù†, Ù¹Ú¾ÛŒÚ©, Ú©ÙˆØ¬ÛŒ, Ù†ÛÛŒÚº, Ú†Ø§ÛÛŒÛ’]\n",
              "1                                                                                                                                                                                                                                      [Ú†Ù„, Ù…ÛÙ…Ø§Ù†ÙˆÚº, Ú©Ú¾Ø§Ù†Ø§, Ø³Ø±Ùˆ, Ú†Ú‘ÛŒÙ„, Ú†Ø§Ú†ÛŒ, Ù†ÙˆÚº, Ø¯Ø³Ø¯ÛŒ, Ø§Úº]\n",
              "2    [Ú©Ø§Ù…Ø±Ø§Ù†, Ø®Ø§Ù†, Ø§Ù¾Ú©ÛŒ, Ø¯Ù†, Ø¨Ú¾Ø±ÛŒÛ, Ø²Ù…Û, Ø¯Ø§Ø±ÛŒ, Ù„Ú¯Ø§Ø¦ÛŒ, Ø§Ù¾ÙˆØ²ÛŒØ´Ù†, Ú©Ø±Ø¯Ø§Ø±, Ú©Ø´ÛŒ, Ø§ÙˆØ±Ø§Ø³, Ù¾Ø±Ø¨Ú¾ÙˆÙ†Ú©Ù†Ø§ÛÛ’Ø§Ù¾, Ø®ÙˆØ´Ø§Ù…Ø¯Ú¯Ø±ÛŒ, ÙˆÚ†Ø§Ù¾Ù„ÙˆØ³ÛŒ, Ø³Û’Ø§ÙˆØ±Ú©ØªÙ†ÛŒ, Ø¯ÙˆÙ„Øª, Ú©Ù…Ø§Ù†Ø§Ú†Ø§ÛØªÛ’ÛÛŒÚº, Ù…ÙˆÙ¹Ø±Ø³Ø§Ø¦ÛŒÚ©Ù„, Ø³Û’Ù¾ÛŒØ¬Ø§Ø±Ùˆ, Ù¾Ø±Ø§ÚˆÙˆ, Ú©Û’Ø³ÙØ±Ù…ÛŒÚº, Ø¶Ù…ÛŒØ±Ú©ÛŒ, Ù„Ø§Ø´, Ø³Û’Ø§Ù¹Ú¾ØªÛŒ, Ø¨Ø¯Ø¨ÙˆØ§Ù¾, Ù†Ø§Ú©, Ù†ÛÛŒÚº, Ú©Ø±ØªÛŒ, Ù†ÙˆÙ¹, Ø³Ø¨, Ø³Û’Ø§Ù„ØªØ¬Ø§Ú¯Ø²Ø§Ø±Ø´, ÛÛ’ÛÙ…ÛŒÚº, ÙØ§Ù„ÙˆÚ©Ø±ÛŒÚº, Ø´Ú©Ø±ÛŒÛ]\n",
              "4                                                                                                                                                                                                                                  [Ù…Ø±Ø§Ø¯, Ø¹Ù„ÛŒ, Ø´Ø§Û, Ø¨Ú¾ÛŒØ³, ÚˆÛŒ, Ø¬ÛŒ, Ø§Ø¦ÛŒ, Ø§ÛŒØ³, Ø§Ø¦ÛŒ, Ø­Ø§Ù…Ø¯, Ù…ÛŒØ±]\n",
              "5                                                                                                                                                                                                                                                              [Ù‚Ø§Ø¨Ù„, Ø§Ø¹ØªØ¨Ø§Ø±, Ù‚Ø§ØªÙ„, Ø§Ø¹ØªØ¨Ø§Ø±]\n",
              "Name: tokenized_text, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokenized_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Ù„ÛŒÙ†Û’, Ø¯Û’, Ø´Ø§Ø¯ÛŒ, ÙØ³Ø§Ø¯Ù†, Ù¹Ú¾ÛŒÚ©, Ú©ÙˆØ¬ÛŒ, Ù†ÛÛŒÚº, Ú†Ø§ÛÛŒÛ’]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Ú†Ù„, Ù…ÛÙ…Ø§Ù†ÙˆÚº, Ú©Ú¾Ø§Ù†Ø§, Ø³Ø±Ùˆ, Ú†Ú‘ÛŒÙ„, Ú†Ø§Ú†ÛŒ, Ù†ÙˆÚº, Ø¯Ø³Ø¯ÛŒ, Ø§Úº]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[Ú©Ø§Ù…Ø±Ø§Ù†, Ø®Ø§Ù†, Ø§Ù¾Ú©ÛŒ, Ø¯Ù†, Ø¨Ú¾Ø±ÛŒÛ, Ø²Ù…Û, Ø¯Ø§Ø±ÛŒ, Ù„Ú¯Ø§Ø¦ÛŒ, Ø§Ù¾ÙˆØ²ÛŒØ´Ù†, Ú©Ø±Ø¯Ø§Ø±, Ú©Ø´ÛŒ, Ø§ÙˆØ±Ø§Ø³, Ù¾Ø±Ø¨Ú¾ÙˆÙ†Ú©Ù†Ø§ÛÛ’Ø§Ù¾, Ø®ÙˆØ´Ø§Ù…Ø¯Ú¯Ø±ÛŒ, ÙˆÚ†Ø§Ù¾Ù„ÙˆØ³ÛŒ, Ø³Û’Ø§ÙˆØ±Ú©ØªÙ†ÛŒ, Ø¯ÙˆÙ„Øª, Ú©Ù…Ø§Ù†Ø§Ú†Ø§ÛØªÛ’ÛÛŒÚº, Ù…ÙˆÙ¹Ø±Ø³Ø§Ø¦ÛŒÚ©Ù„, Ø³Û’Ù¾ÛŒØ¬Ø§Ø±Ùˆ, Ù¾Ø±Ø§ÚˆÙˆ, Ú©Û’Ø³ÙØ±Ù…ÛŒÚº, Ø¶Ù…ÛŒØ±Ú©ÛŒ, Ù„Ø§Ø´, Ø³Û’Ø§Ù¹Ú¾ØªÛŒ, Ø¨Ø¯Ø¨ÙˆØ§Ù¾, Ù†Ø§Ú©, Ù†ÛÛŒÚº, Ú©Ø±ØªÛŒ, Ù†ÙˆÙ¹, Ø³Ø¨, Ø³Û’Ø§Ù„ØªØ¬Ø§Ú¯Ø²Ø§Ø±Ø´, ÛÛ’ÛÙ…ÛŒÚº, ÙØ§Ù„ÙˆÚ©Ø±ÛŒÚº, Ø´Ú©Ø±ÛŒÛ]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Ù…Ø±Ø§Ø¯, Ø¹Ù„ÛŒ, Ø´Ø§Û, Ø¨Ú¾ÛŒØ³, ÚˆÛŒ, Ø¬ÛŒ, Ø§Ø¦ÛŒ, Ø§ÛŒØ³, Ø§Ø¦ÛŒ, Ø­Ø§Ù…Ø¯, Ù…ÛŒØ±]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[Ù‚Ø§Ø¨Ù„, Ø§Ø¹ØªØ¨Ø§Ø±, Ù‚Ø§ØªÙ„, Ø§Ø¹ØªØ¨Ø§Ø±]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 283
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tf-IDF"
      ],
      "metadata": {
        "id": "OMGGE-xzWy3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# TF-IDF Vectorization\n",
        "\n",
        "# Initialize the TF-IDF vectorizer\n",
        "vectorizer  = TfidfVectorizer()\n",
        "\n",
        "# Fit and transform the cleaned text\n",
        "tfidf_matrix = vectorizer.fit_transform(data['lemmatized_text'])\n",
        "\n",
        "# Get the words corresponding to the features\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Create a DataFrame to store the TF-IDF scores\n",
        "tfidf_scores = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)\n",
        "\n",
        "# Sum the scores for each term across all documents\n",
        "sum_tfidf_scores = tfidf_scores.sum(axis=0)\n",
        "\n",
        "# Sort the scores and get the top 10 terms\n",
        "top_tfidf_terms = sum_tfidf_scores.nlargest(10)\n",
        "\n",
        "# Display the top 10 words with the highest TF-IDF scores\n",
        "print(top_tfidf_terms)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWTtMr0zW4U6",
        "outputId": "b0ed8573-10ec-4178-b9f9-10ba0a3d4006"
      },
      "execution_count": 284,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ù†ÛÛŒÚº    534.109678\n",
            "Ú©ÛÙ†Ø§    435.896408\n",
            "Ú©Ø±Ù†Ø§    405.821071\n",
            "Ø±ÛÙ†Ø§    402.511894\n",
            "Ù„ÛŒÙ†Ø§    331.921184\n",
            "Ù¾Ø±Ù†Ø§    324.349406\n",
            "Ù…ÛŒÚº     291.783109\n",
            "Ø¯ÛŒÙ†Ø§    289.974836\n",
            "Ù„Ú¯Ù†Ø§    261.155599\n",
            "Ù†Ø§      231.480772\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word2Vec"
      ],
      "metadata": {
        "id": "U_weRpEgW6L5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the Word2Vec model\n",
        "word2vec_model = Word2Vec(sentences=data['tokenized_text'], vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Save the model\n",
        "word2vec_model.save(\"word2vec_urdu.model\")"
      ],
      "metadata": {
        "id": "MPswaIksW90f"
      },
      "execution_count": 285,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**N-grams Analysis**(Unigram, Bigram, and Trigram Analysis)"
      ],
      "metadata": {
        "id": "GMkxIFbJdd6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer1  = TfidfVectorizer()\n",
        "# For Unigrams, Bigrams, and Trigrams\n",
        "vectorizer1 = CountVectorizer(ngram_range=(1, 3))  # (1, 3) for Unigrams, Bigrams, and Trigrams\n",
        "ngram_matrix = vectorizer1.fit_transform(data['lemmatized_text'])\n",
        "\n",
        "# Convert to DataFrame\n",
        "ngram_df = pd.DataFrame(ngram_matrix.toarray(), columns=vectorizer1.get_feature_names_out())\n",
        "\n",
        "# Sum the counts for each n-gram across all documents\n",
        "ngram_sums = ngram_df.sum(axis=0)\n",
        "\n",
        "# Separate unigrams, bigrams, and trigrams\n",
        "unigram_sums = ngram_sums[ngram_sums.index.str.split(' ').str.len() == 1]\n",
        "bigram_sums = ngram_sums[ngram_sums.index.str.split(' ').str.len() == 2]\n",
        "trigram_sums = ngram_sums[ngram_sums.index.str.split(' ').str.len() == 3]\n",
        "\n",
        "# Get top 10 unigrams, bigrams, and trigrams\n",
        "top_unigrams = unigram_sums.nlargest(10)\n",
        "top_bigrams = bigram_sums.nlargest(10)\n",
        "top_trigrams = trigram_sums.nlargest(10)\n",
        "\n",
        "# Display the top 10 unigrams, bigrams, and trigrams with their frequencies\n",
        "print(\"\\nTop 10 Unigrams:\")\n",
        "print(top_unigrams)\n",
        "\n",
        "print(\"\\nTop 10 Bigrams:\")\n",
        "print(top_bigrams)\n",
        "\n",
        "print(\"\\nTop 10 Trigrams:\")\n",
        "print(top_trigrams)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21B4QeNQcN7h",
        "outputId": "147968d6-1d2b-4541-ded0-2710e25a6adf"
      },
      "execution_count": 286,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 10 Unigrams:\n",
            "Ù†ÛÛŒÚº    4442\n",
            "Ú©ÛÙ†Ø§    3903\n",
            "Ú©Ø±Ù†Ø§    3529\n",
            "Ø±ÛÙ†Ø§    3118\n",
            "Ù¾Ø±Ù†Ø§    2760\n",
            "Ù„ÛŒÙ†Ø§    2383\n",
            "Ø¯ÛŒÙ†Ø§    2054\n",
            "Ù…ÛŒÚº     1992\n",
            "Ù„Ú¯Ù†Ø§    1584\n",
            "ÙˆØ§Ù„Ø§    1481\n",
            "dtype: int64\n",
            "\n",
            "Top 10 Bigrams:\n",
            "Ø¹Ù…Ø±Ø§Ù† Ø®Ø§Ù†     502\n",
            "Ù†ÙˆØ§Ø² Ø´Ø±ÛŒÙ     449\n",
            "Ø§Ø¦ÛŒ Ø¬ÛŒÙ†Ø§      323\n",
            "Ø³Ù†Ø¯Ú¾ Ù¾ÙˆÙ„ÛŒØ³    299\n",
            "Ù¾Ø±Ù†Ø§ ØªÙ†Ù‚ÛŒØ¯    244\n",
            "Ø§Ø±Ù…ÛŒ Ú†ÛŒÙ      224\n",
            "Ø¯ÛŒÚ©Ú¾ Ù†Ø§       206\n",
            "Ú©Ø±Ù†Ø§ ÙˆØ§Ù„Ø§     195\n",
            "Ú©ÛÙ†Ø§ Ú©ÛÙ†Ø§     194\n",
            "Ù…Ø± Ù†Ø§         192\n",
            "dtype: int64\n",
            "\n",
            "Top 10 Trigrams:\n",
            "Ø§Ø¦ÛŒ Ø¬ÛŒÙ†Ø§ Ø³Ù†Ø¯Ú¾      118\n",
            "Ù¾ÛŒÙ†Ø§ Ù¹ÛŒ Ø§Ø¦ÛŒ        115\n",
            "ØµÙ„ÛŒ Ø§Ù„Ù„Û Ø¹Ù„ÛŒÛ       95\n",
            "Ø¹Ù„ÛŒÛ ÙˆØ§Ù„Û ÙˆØ³Ù„Ù…      93\n",
            "Ù¾ÛŒÙ†Ø§ ÚˆÛŒ Ø§ÛŒÙ…         88\n",
            "Ù¾Ø±Ù†Ø§ ØªÙ†Ù‚ÛŒØ¯ Ú©Ø±Ù†Ø§     85\n",
            "Ø§Ù„Ù„Û Ø¹Ù„ÛŒÛ ÙˆØ§Ù„Û      84\n",
            "Ø¬Ø²Ø§Ú© Ø§Ù„Ù„Û Ø®ÛŒØ±       76\n",
            "Ø§Ø¦ÛŒ Ø¬ÛŒÙ†Ø§ Ø§ØºÙˆØ§       73\n",
            "ÙØ§Ù„Ùˆ Ú©Ø±Ù†Ø§ ÙØ§Ù„Ùˆ      72\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sentiment Classification Model**"
      ],
      "metadata": {
        "id": "ewx4d8fcdmsT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Building"
      ],
      "metadata": {
        "id": "bir8Bbbz_Yep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split the data into features and target\n",
        "X = tfidf_matrix  # You can also use ngram_matrix or features from Word2Vec\n",
        "y = data['is_sarcastic']  # Assuming this is your sentiment label\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LwSZFPBdrjh",
        "outputId": "7cfd6dd8-73c2-4444-bc83-259533e43009"
      },
      "execution_count": 287,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7861437908496732\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.78      0.78      0.78      1831\n",
            "         1.0       0.80      0.79      0.79      1994\n",
            "\n",
            "    accuracy                           0.79      3825\n",
            "   macro avg       0.79      0.79      0.79      3825\n",
            "weighted avg       0.79      0.79      0.79      3825\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction on new input"
      ],
      "metadata": {
        "id": "NHNnYAvz_cA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(new_input):\n",
        "    # Preprocess the input\n",
        "    processed_input = preprocess_text(new_input)\n",
        "    processed_input = urdu_text_processing.lemmatize_sentence(processed_input)\n",
        "\n",
        "    # Print processed input\n",
        "    print(f\"Processed input: {processed_input}\")\n",
        "\n",
        "    # Vectorize the processed input\n",
        "    input_vectorized = vectorizer.transform([processed_input])  # Use transform() for new data\n",
        "\n",
        "    # Make a prediction\n",
        "    prediction = model.predict(input_vectorized)\n",
        "\n",
        "    return prediction[0]\n"
      ],
      "metadata": {
        "id": "96hIKzl6f5S1"
      },
      "execution_count": 288,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "new_sentence = \"Ø¨ÛØª Ø§Ú†Ú¾Ø§ Ú©Ø§Ù… Ú©ÛŒØ§ØŒ ÛØ± Ø³ÙˆØ§Ù„ ØºÙ„Ø· Ø¯ÛŒØ§!\"\n",
        "predicted_sentiment = predict_sentiment(new_sentence)\n",
        "if predicted_sentiment == 1:\n",
        "    print(\"The sentiment is sarcastic\")\n",
        "else:\n",
        "    print(\"The sentiment is not sarcastic.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkrwtP7vgZUJ",
        "outputId": "bc246351-e93b-484c-996f-9c3af97da01e"
      },
      "execution_count": 289,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed input: Ø¨ÛØª Ø§Ú†Ú¾Ø§ Ú©Ø§Ù… Ú©ÛŒØ§ ÛØ±Ù†Ø§ Ø³ÙˆØ§Ù„ ØºÙ„Ø· Ø¯ÛŒØ§\n",
            "The sentiment is sarcastic\n"
          ]
        }
      ]
    }
  ]
}